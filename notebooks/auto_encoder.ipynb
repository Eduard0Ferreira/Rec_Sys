{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "matrix = ml.get_matrix()# Autoencoder\n",
    "- Auto = self\n",
    "- encode = convert into a different form\n",
    "- Autoencoder = a system that teaches itself how to encode information\n",
    "- Number outputs correspond to the entry from the model\n",
    "\n",
    "# Structure of the layers\n",
    "- Encode: input > layers > bottleneck or latent code (central node)\n",
    "\n",
    "#  Goal of autoencoder:\n",
    "- Get the output to match the input closer possible\n",
    "- data compression of dimension reduction\n",
    "- data cleaning (denoising, despeckling, occlusion)  \n",
    "- feature extraction\n",
    "- anomaly / fraud detection\n",
    "- pretraining deep or complex models   \n"
   ],
   "id": "f9ef06e28206ee28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T00:41:01.366352Z",
     "start_time": "2024-05-07T00:41:01.362332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as weight_init\n",
    "import torch.utils.data\n",
    "from torch._export.db.examples.type_reflection_method import A\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy.sparse import coo_matrix\n",
    "import torch.nn.parallel\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ],
   "id": "50d23d1269728be3",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T00:25:20.905005Z",
     "start_time": "2024-05-07T00:25:20.871378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from preprocess.preprocess import MovieLens\n",
    "\n",
    "ml = MovieLens()"
   ],
   "id": "1f4339e1b6fb0e54",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T00:34:26.484770Z",
     "start_time": "2024-05-07T00:34:26.480949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom dataset class for loading sparse user-item interaction matrix\n",
    "class SparseMatrixDataset(Dataset):\n",
    "    def __init__(self, matrix):\n",
    "        self.matrix = matrix  # Convert matrix to COO format for efficient indexing\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matrix)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.matrix[idx]"
   ],
   "id": "c976e2eec1f88e2f",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T00:34:27.810222Z",
     "start_time": "2024-05-07T00:34:27.806441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_loader = ml.dataset_encoder(batch_size=32)\n",
    "n_users, n_items = ml.num_user_item()"
   ],
   "id": "30c1144e45f7baaf",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T00:34:28.229961Z",
     "start_time": "2024-05-07T00:34:28.226637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, n_enc, n_bottle):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        #input layer\n",
    "        self.input = nn.Linear(n_items, n_enc)\n",
    "\n",
    "        ### encoder layer\n",
    "        self.encoding = nn.Linear(n_enc, n_bottle)\n",
    "\n",
    "        ### bottleneck layer\n",
    "        self.bottleneck = nn.Linear(n_bottle, n_enc)\n",
    "\n",
    "        ### decoder layer\n",
    "        self.decoding = nn.Linear(n_enc, n_items)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.encoding(x))\n",
    "        x = F.relu(self.bottleneck(x))\n",
    "        y = torch.sigmoid(self.decoding(x))\n",
    "        return y"
   ],
   "id": "ce064cad86347fe",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T00:34:28.987636Z",
     "start_time": "2024-05-07T00:34:28.958132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set hyperparameters\n",
    "n_enc = 256\n",
    "n_bottle = 128\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "model = AutoEncoder(n_enc, n_bottle)\n",
    "# Define loss function and optimizer\n",
    "loss_fun = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "14e780472cc41af6",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T00:34:29.808562Z",
     "start_time": "2024-05-07T00:34:29.714790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and preprocess your sparse user-item interaction matrix\n",
    "# Example:\n",
    "sparse_matrix = ml.get_matrix().values\n",
    "matrix_shape = sparse_matrix.shape\n",
    "train_dataset = SparseMatrixDataset(coo_matrix(sparse_matrix))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "189c526514667c0d",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T00:44:42.368952Z",
     "start_time": "2024-05-07T00:44:42.307939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        print(data[2].shape)\n",
    "        inputs = data[0].to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fun(outputs, inputs)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ],
   "id": "2350ceac52ba0ff2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x32 and 9724x256)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[70], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Calculate the loss\u001B[39;00m\n\u001B[1;32m     13\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fun(outputs, inputs)\n",
      "File \u001B[0;32m~/PycharmProjects/Rec_Model/.rec_sys/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Rec_Model/.rec_sys/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[51], line 19\u001B[0m, in \u001B[0;36mAutoEncoder.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 19\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     20\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoding(x))\n\u001B[1;32m     21\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbottleneck(x))\n",
      "File \u001B[0;32m~/PycharmProjects/Rec_Model/.rec_sys/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Rec_Model/.rec_sys/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Rec_Model/.rec_sys/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1x32 and 9724x256)"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd7fdbe0ab4fd692"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
