{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Autoencoder\n",
    "- Auto = self\n",
    "- encode = convert into a different form\n",
    "- Autoencoder = a system that teaches itself how to encode information\n",
    "- Number outputs correspond to the entry from the model\n",
    "\n",
    "# Structure of the layers\n",
    "- Encode: input > layers > bottleneck or latent code (central node)\n",
    "\n",
    "#  Goal of autoencoder:\n",
    "- Get the output to match the input closer possible\n",
    "- data compression of dimension reduction\n",
    "- data cleaning (denoising, despeckling, occlusion)  \n",
    "- feature extraction\n",
    "- anomaly / fraud detection\n",
    "- pretraining deep or complex models   \n"
   ],
   "id": "f9ef06e28206ee28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:48:39.955342Z",
     "start_time": "2024-05-11T13:48:38.639587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ],
   "id": "50d23d1269728be3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:48:44.377477Z",
     "start_time": "2024-05-11T13:48:44.005345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from preprocess.preprocess import MovieLens\n",
    "\n",
    "ml = MovieLens()"
   ],
   "id": "e9ad911cfd87ec5c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:11:38.794959Z",
     "start_time": "2024-05-11T14:11:38.736018Z"
    }
   },
   "cell_type": "code",
   "source": "train_loader = ml.dataset_encoder(32)",
   "id": "b1a6de576df76dd",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:11:48.609417Z",
     "start_time": "2024-05-11T14:11:48.605905Z"
    }
   },
   "cell_type": "code",
   "source": "x = next(iter(train_loader))",
   "id": "b5ecc527ae526e10",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:37:09.020871Z",
     "start_time": "2024-05-03T18:37:09.018906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, num_features, embedding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, embedding_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ],
   "id": "88496a9fbd99452d",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define model, optimizer, and loss function\n",
    "def train_model(num_features, embedding_dim, num_epochs):\n",
    "    model = Autoencoder(num_features, embedding_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for user_ratings in training_data:  # Assuming training_data is a loader for user-item interactions\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            encoded, decoded = model(user_ratings)\n",
    "            loss = criterion(decoded, user_ratings)  # Reconstruct the user ratings\n",
    "            # Backward pass and update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        # Print training progress (optional)matrix = self.df_ratings[['userId', 'movieId', 'rating']]\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")"
   ],
   "id": "6ca96868e178c339",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# After training, extract user embeddings for recommendation\n",
    "user_embeddings = []\n",
    "for user_ratings in validation_data:  # Can use test data as well\n",
    "    encoded, _ = model(user_ratings)\n",
    "    user_embeddings.append(encoded.detach())  # Detach from computation graph\n",
    "\n"
   ],
   "id": "a060999c39e89246"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Example of using user embeddings with another model (replace with your model)\n",
    "class LogisticRegressionRecommender(nn.Module):\n",
    "    def __init__(self, num_features, embedding_dim, num_items):\n",
    "        super(LogisticRegressionRecommender, self).__init__()\n",
    "        self.linear = nn.Linear(num_features + embedding_dim, num_items)\n",
    "\n",
    "    def forward(self, user_features, user_embedding):\n",
    "        combined_features = torch.cat((user_features, user_embedding), dim=1)\n",
    "        return torch.sigmoid(self.linear(combined_features))\n",
    "\n",
    "# ... (train and use the LogisticRegressionRecommender model)\n"
   ],
   "id": "fb38e734bf3ab442"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
