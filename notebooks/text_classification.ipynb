{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T22:38:46.342376Z",
     "start_time": "2024-05-15T22:38:46.073388Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:38:47.619079Z",
     "start_time": "2024-05-15T22:38:46.803205Z"
    }
   },
   "cell_type": "code",
   "source": "from preprocess.text_preprocess import Preprocesstext",
   "id": "a25774224b4f86ce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:39:50.736714Z",
     "start_time": "2024-05-15T23:39:50.734061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ],
   "id": "eb5115157d6a780b",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:40:12.711899Z",
     "start_time": "2024-05-15T22:40:12.544189Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('../../../Dataset/articles/train.csv')",
   "id": "1f4361566788b50b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:54:24.114667Z",
     "start_time": "2024-05-15T22:54:24.107841Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "75133abdcb72722c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance                                     clean_abstract  \n",
       "0                     0  predict model allow subject specif infer analy...  \n",
       "1                     0  rotat invari translat invari great valu imag r...  \n",
       "2                     0  introduc develop notion spheric polyharmon nat...  \n",
       "3                     0  stochast landau lifshitz gilbert llg equat cou...  \n",
       "4                     0  fourier transform infra red ftir spectrum samp...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "      <th>clean_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>predict model allow subject specif infer analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rotat invari translat invari great valu imag r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>introduc develop notion spheric polyharmon nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>stochast landau lifshitz gilbert llg equat cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fourier transform infra red ftir spectrum samp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:40:15.623400Z",
     "start_time": "2024-05-15T22:40:15.620338Z"
    }
   },
   "cell_type": "code",
   "source": "categories = df.iloc[:, 3:].columns",
   "id": "8799698d3cd33e48",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:40:16.219378Z",
     "start_time": "2024-05-15T22:40:16.216888Z"
    }
   },
   "cell_type": "code",
   "source": "prep_text = Preprocesstext()",
   "id": "402385b2113b4409",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:44:40.439543Z",
     "start_time": "2024-05-15T22:40:17.144486Z"
    }
   },
   "cell_type": "code",
   "source": "df['clean_abstract'] = df['ABSTRACT'].apply(lambda x: prep_text.start(x))",
   "id": "a0a9446cd4356e59",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:54:29.244743Z",
     "start_time": "2024-05-15T22:54:29.237588Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "d0098139a67b1437",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance                                     clean_abstract  \n",
       "0                     0  predict model allow subject specif infer analy...  \n",
       "1                     0  rotat invari translat invari great valu imag r...  \n",
       "2                     0  introduc develop notion spheric polyharmon nat...  \n",
       "3                     0  stochast landau lifshitz gilbert llg equat cou...  \n",
       "4                     0  fourier transform infra red ftir spectrum samp...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "      <th>clean_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>predict model allow subject specif infer analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rotat invari translat invari great valu imag r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>introduc develop notion spheric polyharmon nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>stochast landau lifshitz gilbert llg equat cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fourier transform infra red ftir spectrum samp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:54:38.775619Z",
     "start_time": "2024-05-15T22:54:38.767345Z"
    }
   },
   "cell_type": "code",
   "source": "train, test = train_test_split(df, random_state=42, test_size=0.2, shuffle=True)",
   "id": "a7e6d430608b556b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:54:39.603994Z",
     "start_time": "2024-05-15T22:54:39.601592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = train.clean_abstract\n",
    "X_test = test.clean_abstract"
   ],
   "id": "59d2610e477c515d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:54:40.283911Z",
     "start_time": "2024-05-15T22:54:40.281171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NB_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "        fit_prior=True, class_prior=None))),\n",
    "])\n"
   ],
   "id": "a3049c328183e53",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:54:45.790367Z",
     "start_time": "2024-05-15T22:54:40.983618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    NB_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = NB_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ],
   "id": "ec54036eae69996d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing Computer Science\n",
      "Test accuracy is 0.8402860548271752\n",
      "... Processing Physics\n",
      "Test accuracy is 0.9048867699642431\n",
      "... Processing Mathematics\n",
      "Test accuracy is 0.8576877234803337\n",
      "... Processing Statistics\n",
      "Test accuracy is 0.8054827175208582\n",
      "... Processing Quantitative Biology\n",
      "Test accuracy is 0.9709177592371872\n",
      "... Processing Quantitative Finance\n",
      "Test accuracy is 0.9892729439809297\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:54:48.234648Z",
     "start_time": "2024-05-15T22:54:48.081512Z"
    }
   },
   "cell_type": "code",
   "source": "prediction = NB_pipeline.predict(X_test)",
   "id": "4a62a04c639e2f6",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:00:48.820551Z",
     "start_time": "2024-05-15T23:00:43.935175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SVC_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(dual='auto'), n_jobs=1)),\n",
    "])\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    SVC_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = SVC_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ],
   "id": "441f81df0f1e2323",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing Computer Science\n",
      "Test accuracy is 0.8457687723480334\n",
      "... Processing Physics\n",
      "Test accuracy is 0.9289630512514899\n",
      "... Processing Mathematics\n",
      "Test accuracy is 0.8908224076281287\n",
      "... Processing Statistics\n",
      "Test accuracy is 0.8724672228843862\n",
      "... Processing Quantitative Biology\n",
      "Test accuracy is 0.9711561382598332\n",
      "... Processing Quantitative Finance\n",
      "Test accuracy is 0.9930870083432658\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:01:05.313739Z",
     "start_time": "2024-05-15T23:00:58.978054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "])\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = LogReg_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ],
   "id": "ffde43de00a0cf7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing Computer Science\n",
      "Test accuracy is 0.8579261025029797\n",
      "... Processing Physics\n",
      "Test accuracy is 0.9270560190703218\n",
      "... Processing Mathematics\n",
      "Test accuracy is 0.8955899880810488\n",
      "... Processing Statistics\n",
      "Test accuracy is 0.8796185935637664\n",
      "... Processing Quantitative Biology\n",
      "Test accuracy is 0.9718712753277712\n",
      "... Processing Quantitative Finance\n",
      "Test accuracy is 0.9911799761620977\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://jovian.ml/kyawkhaung/1-titles-only-for-medium/v/1&cellId=10?source=post_page-----47011a7313b9--------------------------------",
   "id": "ddc1a56d0e676171"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:02:56.600525Z",
     "start_time": "2024-05-15T23:02:55.252622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ],
   "id": "38512054c0305021",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:04:09.547244Z",
     "start_time": "2024-05-15T23:04:09.544290Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "id": "bc844e8ce25553a1",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T18:17:54.895498Z",
     "start_time": "2024-05-15T18:17:54.876948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['WORD_COUNT'] = df['TITLE'].apply(lambda x: len(x.split()))\n",
    "df.head()"
   ],
   "id": "2605af8870acdd37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  WORD_COUNT  \n",
       "0                     0           4  \n",
       "1                     0           4  \n",
       "2                     0           8  \n",
       "3                     0           9  \n",
       "4                     0          20  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "      <th>WORD_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:02:45.030661Z",
     "start_time": "2024-05-15T23:02:45.022100Z"
    }
   },
   "cell_type": "code",
   "source": "df['target_list'] = df[['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology','Quantitative Finance']].values.tolist()",
   "id": "3c91311549085304",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:02:47.155139Z",
     "start_time": "2024-05-15T23:02:47.143740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df2 = df[['TITLE', 'target_list']].copy()\n",
    "df2.head()"
   ],
   "id": "4e928072a2e328f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               TITLE         target_list\n",
       "0        Reconstructing Subject-Specific Effect Maps  [1, 0, 0, 0, 0, 0]\n",
       "1                 Rotation Invariance Neural Network  [1, 0, 0, 0, 0, 0]\n",
       "2  Spherical polyharmonics and Poisson kernels fo...  [0, 0, 1, 0, 0, 0]\n",
       "3  A finite element approximation for the stochas...  [0, 0, 1, 0, 0, 0]\n",
       "4  Comparative study of Discrete Wavelet Transfor...  [1, 0, 0, 1, 0, 0]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>target_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:47:05.193166Z",
     "start_time": "2024-05-15T23:47:02.000153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 16\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', force_download=True)"
   ],
   "id": "21954c3698926a2b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduardo/PycharmProjects/Rec_Model/.rec_sys/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b9ccd38a0eb47fdab8174bf84d4bf15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb6b5aa2872946438d3fd885901672b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61bc1bbc9ee04be3a2bc40139a403a72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a473c955913545209c40d2c47cdbe1df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:47:05.197690Z",
     "start_time": "2024-05-15T23:47:05.194215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.title = dataframe['TITLE']\n",
    "        self.targets = self.data.target_list\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.title[index])\n",
    "        title = \" \".join(title.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ],
   "id": "3a8393665f64c997",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:47:07.072234Z",
     "start_time": "2024-05-15T23:47:07.062894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_size = 0.8\n",
    "train_dataset = df2.sample(frac=train_size, random_state=200)\n",
    "valid_dataset = df2.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df2.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(valid_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
    "validation_set = CustomDataset(valid_dataset, tokenizer, MAX_LEN)"
   ],
   "id": "3d9e9999b189946f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (20972, 2)\n",
      "TRAIN Dataset: (16778, 2)\n",
      "TEST Dataset: (4194, 2)\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:47:07.561968Z",
     "start_time": "2024-05-15T23:47:07.558574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "               'shuffle': False,\n",
    "               'num_workers': 0\n",
    "               }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validation_loader = DataLoader(validation_set, **test_params)"
   ],
   "id": "a5851c99482ef628",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:47:15.201022Z",
     "start_time": "2024-05-15T23:47:14.538665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 6)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        # print(\"Shape of ids:\", ids.shape)\n",
    "        # print(\"Shape of mask:\", mask.shape)\n",
    "        # print(\"Shape of token_type_ids:\", token_type_ids.shape)\n",
    "\n",
    "        outputs = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        # print(\"Type of outputs[0]:\", type(outputs[0]))\n",
    "        # print(\"Shape of outputs[0]:\", outputs[0].shape)\n",
    "        \n",
    "        output_1 = outputs[1]\n",
    "        # print(\"Shape of output_1:\", output_1.shape), force_download=True)\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 6)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        # print(\"Shape of ids:\", ids.shape)\n",
    "        # print(\"Shape of mask:\", mask.shape)\n",
    "        # print(\"Shape of token_type_ids:\", token_type_ids.shape)\n",
    "\n",
    "        outputs = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        # print(\"Type of outputs[0]:\", type(outputs[0]))\n",
    "        # print(\"Shape of outputs[0]:\", outputs[0].shape)\n",
    "        \n",
    "        output_1 = outputs[1]\n",
    "        # print(\"Shape of output_1:\", output_1.shape)\n",
    "\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = BERTClass()"
   ],
   "id": "4a8bded9a688e014",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduardo/PycharmProjects/Rec_Model/.rec_sys/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:47:15.205677Z",
     "start_time": "2024-05-15T23:47:15.202418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ],
   "id": "3f162f6811f16141",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:47:16.607362Z",
     "start_time": "2024-05-15T23:47:16.604179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()"
   ],
   "id": "670adadcbd0d28ca",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:12:14.705102Z",
     "start_time": "2024-05-15T23:12:14.702412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil, sys\n",
    "\n",
    "\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ],
   "id": "d25700df7f601ea7",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:12:14.707857Z",
     "start_time": "2024-05-15T23:12:14.705898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#to use as global variables\n",
    "val_targets = []\n",
    "val_outputs = []"
   ],
   "id": "44fec12351e84b4f",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T23:12:14.714946Z",
     "start_time": "2024-05-15T23:12:14.708680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(start_epochs, n_epochs, valid_loss_min_input,\n",
    "                training_loader, validation_loader, model,\n",
    "                optimizer, checkpoint_path, best_model_path):\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = valid_loss_min_input\n",
    "\n",
    "    for epoch in range(start_epochs, n_epochs + 1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        model.train()\n",
    "        print('############# Epoch {}: Training Start   #############'.format(epoch))\n",
    "        for batch_idx, data in enumerate(training_loader):\n",
    "            #print('yyy epoch', batch_idx)\n",
    "            ids = data['ids'].to(device, dtype=torch.long)\n",
    "            mask = data['mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            #if batch_idx%5000==0:\n",
    "            #   print(f'Epoch: {epoch}, Training Loss:  {loss.item()}')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print('before loss data in training', loss.item(), train_loss)\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
    "            #print('after loss data in training', loss.item(), train_loss)\n",
    "\n",
    "        print('############# Epoch {}: Training End     #############'.format(epoch))\n",
    "\n",
    "        print('############# Epoch {}: Validation Start   #############'.format(epoch))\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(validation_loader, 0):\n",
    "                ids = data['ids'].to(device, dtype=torch.long)\n",
    "                mask = data['mask'].to(device, dtype=torch.long)\n",
    "                token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "                targets = data['targets'].to(device, dtype=torch.float)\n",
    "                outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
    "                val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "                val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "\n",
    "            print('############# Epoch {}: Validation End     #############'.format(epoch))\n",
    "            # calculate average losses\n",
    "            #print('before cal avg train loss', train_loss)\n",
    "            train_loss = train_loss / len(training_loader)\n",
    "            valid_loss = valid_loss / len(validation_loader)\n",
    "            # print training/validation statistics \n",
    "            print('Epoch: {} \\tAverage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                train_loss,\n",
    "                valid_loss\n",
    "            ))\n",
    "\n",
    "            # create checkpoint variable and add important data\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'valid_loss_min': valid_loss,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict()\n",
    "            }\n",
    "\n",
    "            # save checkpoint\n",
    "            save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
    "\n",
    "            ## TODO: save the model if validation loss has decreased\n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "                # save checkpoint as best model\n",
    "                save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
    "                valid_loss_min = valid_loss\n",
    "\n",
    "        print('############# Epoch {}  Done   #############\\n'.format(epoch))\n",
    "\n",
    "    return model"
   ],
   "id": "61d6a531d8e1105d",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:26:28.701660Z",
     "start_time": "2024-05-15T23:48:39.082862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint_path = '../models/transformer/current_checkpoint.pt'\n",
    "best_model = '../models/transformer/best_model.pt'\n",
    "trained_model = train_model(1, 4, np.Inf, training_loader, validation_loader, model, optimizer, checkpoint_path,\n",
    "                            best_model)"
   ],
   "id": "3af1a91be8221f98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Epoch 1: Training Start   #############\n",
      "############# Epoch 1: Training End     #############\n",
      "############# Epoch 1: Validation Start   #############\n",
      "############# Epoch 1: Validation End     #############\n",
      "Epoch: 1 \tAverage Training Loss: 0.000628 \tAverage Validation Loss: 0.001988\n",
      "Validation loss decreased (inf --> 0.001988).  Saving model ...\n",
      "############# Epoch 1  Done   #############\n",
      "\n",
      "############# Epoch 2: Training Start   #############\n",
      "############# Epoch 2: Training End     #############\n",
      "############# Epoch 2: Validation Start   #############\n",
      "############# Epoch 2: Validation End     #############\n",
      "Epoch: 2 \tAverage Training Loss: 0.000454 \tAverage Validation Loss: 0.001765\n",
      "Validation loss decreased (0.001988 --> 0.001765).  Saving model ...\n",
      "############# Epoch 2  Done   #############\n",
      "\n",
      "############# Epoch 3: Training Start   #############\n",
      "############# Epoch 3: Training End     #############\n",
      "############# Epoch 3: Validation Start   #############\n",
      "############# Epoch 3: Validation End     #############\n",
      "Epoch: 3 \tAverage Training Loss: 0.000392 \tAverage Validation Loss: 0.001723\n",
      "Validation loss decreased (0.001765 --> 0.001723).  Saving model ...\n",
      "############# Epoch 3  Done   #############\n",
      "\n",
      "############# Epoch 4: Training Start   #############\n",
      "############# Epoch 4: Training End     #############\n",
      "############# Epoch 4: Validation Start   #############\n",
      "############# Epoch 4: Validation End     #############\n",
      "Epoch: 4 \tAverage Training Loss: 0.000344 \tAverage Validation Loss: 0.001764\n",
      "############# Epoch 4  Done   #############\n",
      "\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:26:28.719250Z",
     "start_time": "2024-05-16T00:26:28.702771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_preds = (np.array(val_outputs) > 0.5).astype(int)\n",
    "val_preds"
   ],
   "id": "e2177210fa3ca7bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:26:28.859032Z",
     "start_time": "2024-05-16T00:26:28.720292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy = metrics.accuracy_score(val_targets, val_preds)\n",
    "f1_score_micro = metrics.f1_score(val_targets, val_preds, average='micro')\n",
    "f1_score_macro = metrics.f1_score(val_targets, val_preds, average='macro')\n",
    "print(f\"Accuracy Score = {accuracy}\")\n",
    "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ],
   "id": "61fb865845af078e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.5925608011444922\n",
      "F1 Score (Micro) = 0.7553334386852086\n",
      "F1 Score (Macro) = 0.596094462819834\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:26:28.862368Z",
     "start_time": "2024-05-16T00:26:28.860350Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.metrics import multilabel_confusion_matrix as mcm, classification_report\n",
   "id": "6d57c2b5d25a521e",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:26:28.895216Z",
     "start_time": "2024-05-16T00:26:28.863219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cm_labels = ['Computer Science', 'Physics', 'Mathematics',\n",
    "       'Statistics', 'Quantitative Biology', 'Quantitative Finance']\n",
    "    \n",
    "cm = mcm(val_targets, val_preds)"
   ],
   "id": "50208adcc88386dc",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:26:28.941841Z",
     "start_time": "2024-05-16T00:26:28.896252Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(val_targets, val_preds, zero_division=True))",
   "id": "c55f9266e5043d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      8690\n",
      "           1       0.90      0.75      0.82      5850\n",
      "           2       0.79      0.70      0.74      5620\n",
      "           3       0.68      0.69      0.69      5260\n",
      "           4       0.65      0.14      0.23       655\n",
      "           5       0.66      0.20      0.30       210\n",
      "\n",
      "   micro avg       0.79      0.73      0.76     26285\n",
      "   macro avg       0.74      0.55      0.60     26285\n",
      "weighted avg       0.79      0.73      0.75     26285\n",
      " samples avg       0.82      0.76      0.75     26285\n",
      "\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:28:29.341756Z",
     "start_time": "2024-05-16T00:28:29.338482Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dfe3877a302e3c77",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c5516381d9ec86b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
