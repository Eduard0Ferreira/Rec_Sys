{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T16:49:33.685158Z",
     "start_time": "2024-04-24T16:49:32.124470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "a5c319ca0fcfad60",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T16:49:33.732021Z",
     "start_time": "2024-04-24T16:49:33.689176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_ratings = pd.read_csv('/home/eduardoferreira/PycharmProjects/Rec_Sys/dataset/ml-latest-small/ratings.csv', sep=',')\n",
    "df_movies = pd.read_csv('/home/eduardoferreira/PycharmProjects/Rec_Sys/dataset/ml-latest-small//movies.csv')"
   ],
   "id": "eee7b40899e459bc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T16:49:33.743613Z",
     "start_time": "2024-04-24T16:49:33.732954Z"
    }
   },
   "cell_type": "code",
   "source": "df_user_item = pd.merge(df_ratings, df_movies, on='movieId', how='inner')",
   "id": "b7ea23c65ccef7a6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T16:49:33.758432Z",
     "start_time": "2024-04-24T16:49:33.744832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d = defaultdict(LabelEncoder)\n",
    "cols_cat = ['userId', 'movieId']\n",
    "for c in cols_cat:\n",
    "    d[c].fit(df_user_item[c].unique())\n",
    "    df_user_item[c] = d[c].transform(df_user_item[c])"
   ],
   "id": "d718cb6e272db585",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T16:49:33.778381Z",
     "start_time": "2024-04-24T16:49:33.760032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = df_user_item.groupby('userId').head(-5).reset_index(drop=True)\n",
    "df_val = df_user_item.groupby('userId').tail(5).reset_index(drop=True)"
   ],
   "id": "e93578664c5a65a9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T16:49:33.857706Z",
     "start_time": "2024-04-24T16:49:33.779328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "matrix = df_user_item[['userId', 'movieId', 'rating']]\n",
    "X = list(zip(matrix.userId.values, matrix.movieId.values))\n",
    "y = matrix.rating.values\n",
    "data_t = torch.tensor(X)\n",
    "labels = torch.tensor(y)\n",
    "# labels = labels[:, None]"
   ],
   "id": "b85d8c84abf2ee16",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T17:02:20.553914Z",
     "start_time": "2024-04-24T17:02:20.543820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "\n",
    "# split the data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data_t, labels, test_size=.1)\n",
    "\n",
    "#convert to a pytorch \n",
    "train_dataDataset = TensorDataset(train_data, train_labels)\n",
    "test_dataDataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# train and test dataloaders\n",
    "train_loader = DataLoader(train_dataDataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataDataset, batch_size=test_dataDataset.tensors[0].shape[0])"
   ],
   "id": "f0492d847c3b234c",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T16:49:39.152064Z",
     "start_time": "2024-04-24T16:49:39.147387Z"
    }
   },
   "cell_type": "code",
   "source": "train_labels.shape",
   "id": "24fb7dd22275e183",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90752])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T16:52:32.032836Z",
     "start_time": "2024-04-24T16:52:32.022281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MF(nn.Module):\n",
    "\n",
    "    def __init__(self, num_users, num_items, emb_dim, init):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_embeddings=num_users, embedding_dim=emb_dim)\n",
    "        self.item_emb = nn.Embedding(num_embeddings=num_items, embedding_dim=emb_dim)\n",
    "\n",
    "        self.fc1 = nn.Linear(emb_dim, emb_dim * 4)\n",
    "        self.fc2 = nn.Linear(emb_dim * 4, emb_dim * 2)\n",
    "        self.fc3 = nn.Linear(emb_dim * 2, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # add bias\n",
    "        self.user_bias = nn.Parameter(torch.zeros(num_users))\n",
    "        self.item_bias = nn.Parameter(torch.zeros(num_items))\n",
    "        self.offset = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        if init:\n",
    "            self.user_emb.weight.data.uniform_(0., 0.5)\n",
    "            self.item_emb.weight.data.uniform_(0., 0.5)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.user_emb(user)\n",
    "        item_emb = self.item_emb(item)\n",
    "        element_product = (user_emb * item_emb).sum(1)\n",
    "\n",
    "        # Reshape element_product to match the input size of self.fc1\n",
    "        element_product = element_product.unsqueeze(1)  # Add an extra dimension\n",
    "        element_product = element_product.expand(-1,self.fc1.in_features)  # Expand along the second dimension to match fc1 input size\n",
    "\n",
    "        x = self.relu(self.fc1(element_product))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "\n",
    "        user_b = self.user_bias[user]\n",
    "        item_b = self.item_bias[item]\n",
    "        # element_product += user_b + item_b + self.offset\n",
    "\n",
    "        return x.squeeze() + user_b + item_b + self.offset\n",
    "\n",
    "\n",
    "n_users = len(df_user_item.userId.unique())\n",
    "n_items = len(df_user_item.movieId.unique())\n",
    "mf_model = MF(n_users, n_items, emb_dim=32, init=True)\n",
    "mf_model.to(device)\n",
    "print(mf_model)"
   ],
   "id": "6de97c8a38fc68f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF(\n",
      "  (user_emb): Embedding(610, 32)\n",
      "  (item_emb): Embedding(9724, 32)\n",
      "  (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T17:55:13.303518Z",
     "start_time": "2024-04-24T17:55:13.296964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train the model\n",
    "def train_model(num_epochs):\n",
    "    loss_fun = nn.MSELoss()\n",
    "    optimizer = optim.Adam(mf_model.parameters(), lr=.01)\n",
    "    # initialize accuracies as empties\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # activate training mode\n",
    "        mf_model.train()\n",
    "\n",
    "        # loop over training data batches\n",
    "        batch_loss = []\n",
    "        for X, y in train_loader:\n",
    "            # forward pass and loss\n",
    "            user, item = X[:, 0], X[:, 1]\n",
    "            y_rating = y.to(device, dtype=torch.float)\n",
    "            y_hat = mf_model(user, item)\n",
    "            loss = loss_fun(y_hat, y_rating)\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "        # append the batch loss \n",
    "        train_losses.append(np.mean(loss.item()))\n",
    "        print(f'epoch {epoch + 1} loss batch: {np.mean(batch_loss)}')\n",
    "        # activate testing mode\n",
    "        mf_model.eval()\n",
    "\n",
    "        # extract X,y from test dataloadermore reliable than gradient descent algorithms and their variants, and it reaches convergence at a higher speed.\n",
    "        X, y = next(iter(test_loader))\n",
    "        user_val, item_val = X[:, 0], X[:, 1]\n",
    "        with torch.no_grad():\n",
    "            y_hat = mf_model(user_val, item_val)\n",
    "            loss = loss_fun(y_hat, y)\n",
    "        val_losses.append(loss)\n",
    "\n",
    "    return train_losses, val_losses\n"
   ],
   "id": "2880a41e8abfd723",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T17:58:40.673568Z",
     "start_time": "2024-04-24T17:55:16.406857Z"
    }
   },
   "cell_type": "code",
   "source": "train_losses, val_losses = train_model(num_epochs=50)",
   "id": "bc7bf88441af8a93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss batch: 0.6728309083766763\n",
      "epoch 2 loss batch: 0.6727746597928624\n",
      "epoch 3 loss batch: 0.6716653652520711\n",
      "epoch 4 loss batch: 0.6717485474010112\n",
      "epoch 5 loss batch: 0.6710282233143054\n",
      "epoch 6 loss batch: 0.6710399628021821\n",
      "epoch 7 loss batch: 0.671176732784434\n",
      "epoch 8 loss batch: 0.671170912735553\n",
      "epoch 9 loss batch: 0.6713455743110398\n",
      "epoch 10 loss batch: 0.6709950043595224\n",
      "epoch 11 loss batch: 0.6707278635715396\n",
      "epoch 12 loss batch: 0.6710133705345969\n",
      "epoch 13 loss batch: 0.6711502281163408\n",
      "epoch 14 loss batch: 0.6712276395016228\n",
      "epoch 15 loss batch: 0.6706276588530735\n",
      "epoch 16 loss batch: 0.6711820957943145\n",
      "epoch 17 loss batch: 0.6708902055016693\n",
      "epoch 18 loss batch: 0.6711085352137663\n",
      "epoch 19 loss batch: 0.6708293412358872\n",
      "epoch 20 loss batch: 0.6711000665412803\n",
      "epoch 21 loss batch: 0.671095932215158\n",
      "epoch 22 loss batch: 0.6709081819556832\n",
      "epoch 23 loss batch: 0.6711398279675308\n",
      "epoch 24 loss batch: 0.6710814969201686\n",
      "epoch 25 loss batch: 0.67158181427312\n",
      "epoch 26 loss batch: 0.6704008570006603\n",
      "epoch 27 loss batch: 0.6717113279363164\n",
      "epoch 28 loss batch: 0.6716541519075926\n",
      "epoch 29 loss batch: 0.6712072743221129\n",
      "epoch 30 loss batch: 0.671027340278639\n",
      "epoch 31 loss batch: 0.6701841913846719\n",
      "epoch 32 loss batch: 0.6711447331397591\n",
      "epoch 33 loss batch: 0.6709918916351536\n",
      "epoch 34 loss batch: 0.6714306169823968\n",
      "epoch 35 loss batch: 0.6709426582195863\n",
      "epoch 36 loss batch: 0.6708395626338144\n",
      "epoch 37 loss batch: 0.6709015912078163\n",
      "epoch 38 loss batch: 0.6714107267064672\n",
      "epoch 39 loss batch: 0.6715417221840077\n",
      "epoch 40 loss batch: 0.6714120605390398\n",
      "epoch 41 loss batch: 0.6712240367203068\n",
      "epoch 42 loss batch: 0.6712574123579625\n",
      "epoch 43 loss batch: 0.671470962895661\n",
      "epoch 44 loss batch: 0.6707975983157313\n",
      "epoch 45 loss batch: 0.6717807032451643\n",
      "epoch 46 loss batch: 0.6710694515696701\n",
      "epoch 47 loss batch: 0.6710405857926195\n",
      "epoch 48 loss batch: 0.6707978977681215\n",
      "epoch 49 loss batch: 0.6711546136184539\n",
      "epoch 50 loss batch: 0.6714427774858743\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:30:32.708413Z",
     "start_time": "2024-04-24T21:30:32.558904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Val')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend();\n"
   ],
   "id": "455d353ff84c4749",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(train_losses, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(val_losses, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVal\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T19:05:21.328726Z",
     "start_time": "2024-04-24T19:05:21.187561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_emb_min_w = mf_model.user_emb.weight.min().item()\n",
    "user_emb_max_w = mf_model.user_emb.weight.max().item()\n",
    "item_emb_min_w = mf_model.item_emb.weight.min().item()\n",
    "item_emb_max_w = mf_model.item_emb.weight.max().item()\n",
    "\n",
    "print(f'Emb user min/max w: {user_emb_min_w:0.3f} / {user_emb_max_w:0.3f}')\n",
    "print(f'Emb item min/max w: {item_emb_min_w:0.3f} / {item_emb_max_w:0.3f}')\n",
    "print(f'Preds min/max: {y_ratings.min().item():0.2f} / {y_hat.max().item():0.2f}')\n",
    "print(f'Rating min/max: {yRatings.min().item():0.2f} / {yRatings.max().item():0.2f}')\n",
    "print(preds.detach().cpu().numpy()[:6])\n",
    "print(y_ratings.detach().cpu().numpy()[:6])"
   ],
   "id": "dd4fd62d4a90fed3",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mf_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m user_emb_min_w \u001B[38;5;241m=\u001B[39m \u001B[43mmf_model\u001B[49m\u001B[38;5;241m.\u001B[39muser_emb\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mmin()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m      2\u001B[0m user_emb_max_w \u001B[38;5;241m=\u001B[39m mf_model\u001B[38;5;241m.\u001B[39muser_emb\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m      3\u001B[0m item_emb_min_w \u001B[38;5;241m=\u001B[39m mf_model\u001B[38;5;241m.\u001B[39mitem_emb\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mmin()\u001B[38;5;241m.\u001B[39mitem()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'mf_model' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "876bcd6b995a32bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
